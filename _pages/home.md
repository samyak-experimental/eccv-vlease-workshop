---
layout: project
urltitle:  "Visual Learning and Embodied Agents in Simulation Environments"
title: "Visual Learning and Embodied Agents in Simulation Environments"
categories: eccv, workshop, computer vision, embodied agents, visual learning, simulation environments, robotics, visual navigation, machine learning, natural language processing
permalink: /
favicon: /static/img/embodiedqa/favicon.png
bibtex: true
paper: true
---

<!-- In case, acks are needed, uncomment the following and place in the intro block -->

<!-- acknowledgements: "We are grateful to the developers of PyTorch for building an excellent framework.
We thank Yuxin Wu for help with the House3D environment.
This work was funded in part by NSF CAREER awards to DB and DP, ONR YIP awards
to DP and DB, ONR Grant N00014-14-1-0679 to DB, ONR Grant N00014-16-1-2713 to DP,
an Allen Distinguished Investigator award to DP from the Paul G. Allen Family Foundation,
Google Faculty Research Awards to DP and DB, Amazon Academic Research Awards to DP and DB,
AWS in Education Research grant to DB, and NVIDIA GPU donations to DB. The views and
conclusions contained herein are those of the authors and should not be interpreted as
necessarily representing the official policies or endorsements, either expressed
or implied, of the U.S. Government, or any sponsor." -->

<br>
<div class="row">
  <div class="col-xs-12">
    <center><h1>Visual Learning and Embodied Agents in Simulation Environments</h1></center>
    <center><h2>ECCV 2018 Workshop, Munich, Germany</h2></center>
    <center><span style="color:#e74c3c;font-weight:400;">
      Friday, 13th April, 08:45 AM to 05:30 PM, Room: TBD
    </span></center>
  </div>
</div>

<hr>

<br>
<div class="row">
  <div class="col-xs-12">
    <h2>Introduction</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      Simulation environments are having a profound impact on computer vision and
      artificial intelligence (AI) research. Synthetic environments can be used to generate
      unlimited cheap, labeled data for training data-hungry visual learning algorithms
      for perception tasks such as 3D pose estimation, object detection and
      recognition, semantic segmentation, 3D reconstruction, intuitive
      physics modeling and text localization. In addition, visually-realistic
      simulation environments designed for embodied agents have reignited interest
      in high-level AI tasks such as visual navigation, natural language
      instruction following and embodied question answering. This
      workshop will bring together researchers from computer vision, machine learning,
      natural language processing and robotics to examine the challenges and
      opportunities in this rapidly developing area - using simulation environments to
      develop intelligent embodied agents and other vision-based systems.
    </p>
  </div>
  <!-- <div class="col-xs-12">
    <span style="color:#e74c3c;font-weight:400;">Dec 2017</span> — <a target="_blank" href="https://github.com/facebookresearch/house3d">Code for 3D environments</a> is now available!
  </div> -->
</div> <br>   

<div class="row">
  <div class="col-xs-12">
    <h2>Call for papers</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      We solicit high-quality short (4-page) and long (8-page) paper submissions,
      which may also include a live demo. Demos will provide workshop participants
      with an important opportunity to interact with simulation environments, algorithms
      and agents, to better understand the strengths and limitations of current
      work. All submissions will be peer reviewed. Accepted submissions will be showcased
      in joint poster/demo sessions, with four paper submissions selected for
      spotlight oral presentation. Full papers will be posted on the workshop website
      but will not appear in the official proceedings. Submissions will be separated
      into two tracks. Papers and demos must be submitted to one track only.

      <h3>Visual Learning Track</h3><br>
      <ul>
        <li>Established computer vision tasks using synthetic data (e.g. 3D pose estimation,
            object recognition, object detection, semantic segmentation, text localization, single-image 3D reconstruction and indoor/outdoor scene understanding)</li>
        <li>Novel computer vision tasks using synthetic data</li>
        <li>Understanding physics from visual input</li>
        <li>Domain adaptation from simulators to the real world</li>
      </ul><br>

      <h3>Embodied Agents Track</h3><br>
      <ul>
        <li>Embodied agents operating in simulation environments, including reinforcement
            learning and approaches that use mapping and planning</li>
        <li>Novel datasets / simulators / tasks for embodied agents</li>
        <li>Language-based command of embodied agents, including embodied question
            answering and / or dialog</li>
        <li>Photo-realistic simulations from reconstructed point clouds / 3D meshes</li>
        <li>Simulating interactions with objects in environments</li>
        <li>Domain adaptation for embodied agents</li>
        <li>Simulating people and environment changes</li>
      </ul>

    </p>
  </div>

  <!-- <div class="col-xs-12">
    <span style="color:#e74c3c;font-weight:400;">Dec 2017</span> — <a target="_blank" href="https://github.com/facebookresearch/house3d">Code for 3D environments</a> is now available!
  </div> -->
</div>

<br>
<div class="row">
  <div class="col-xs-12">
    <h2>Schedule</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <ul>
      <li>08:45 AM : Welcome and Introduction</li> 
      <li>09:00 AM : Speaker 1</li> 
      <li>09:25 AM : Speaker 2</li>
      <li>09:50 AM : Speaker 3</li>
      <li>10:15 AM : Coffee + Posters/Demos (Visual Learning Track)</li>
      <li>11:00 AM : Speaker 4</li>
      <li>11:25 AM : Speaker 5</li>
      <li>11:50 AM : Poster Spotlight Presentations (4 × 5 min)</li>
      <li>12:10 PM : Lunch</li>
      <li>13:30 PM : Speaker 6</li>
      <li>13:55 PM : Speaker 7</li>
      <li>14:20 PM : Speaker 8</li>
      <li>14:45 PM : Coffee + Posters/Demos (Embodied Agents Track)</li>
      <li>15:30 PM : Speaker 9</li>
      <li>15:55 PM : Speaker 10</li>
      <li>16:20 PM : Speaker 11</li>
      <li>16:45 PM : Panel Discussion</li>
      <li>17:30 PM : Closing Remarks</li>
    </ul>
  </div>
</div>

<br>
<div class="row">
  <div class="col-xs-12">
    <h2>Invited Speakers</h2>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="{{ "/static/img/people/abhishek.jpg" | prepend:site.baseurl }}">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-md-12">
    <img class="people-pic" style="float:left;margin-right:50px;height:80px;width:80px;" src="/static/img/people/abhishek.jpg">
    <p><b>Sanja Fidler</b> is an Assistant Professor at University of Toronto.
        Her main research interests are 2D and 3D object detection, particularly 
        scalable multi-class detection, object segmentation and image labeling, 
        and (3D) scene understanding.
        She is also interested in the interplay between language and vision.</p>
  </div>
</div><br>

<div class="row">
  <div class="col-xs-12">
    <h2>Important Dates</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <p>20th April : Submission Deadline</p>
    <p>20th April : Acceptance Notification</p>
    <p>20th April : Camera-ready deadline</p>
    <!-- <ul>
      <li>20th April : Submission Deadline</li>
      <li>20th April : Acceptance Notification</li>
      <li>20th April : Camera-ready deadline</li>
    </ul> -->
  </div>
</div><br>

<div class="row">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>
  
  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>
  
  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>

  <div class="row">
  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>
  
  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>
  
  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>

  <div class="col-xs-2">
    <img class="people-pic" src="/static/img/people/abhishek.jpg">
    <div class="people-name">
      <a href="//abhishekdas.com">Abhishek Das</a>
      <h6>Georgia Tech</h6>
    </div>
  </div>

</div>

<hr>

{% if page.acknowledgements %}
<div class="row">
  <div class="col-xs-12">
    <h2>Acknowledgements</h2>
  </div>
</div>
<a name="/acknowledgements"></a>
<div class="row">
  <div class="col-xs-12">
    <p>
      {{ page.acknowledgements }}
    </p>
  </div>
</div>
{% endif %}

<div class="row">
  <div class="col-xs-12">
    <h2>Sponsors</h2>
  </div>
</div>
<a name="/sponsors"></a>
<div class="row">
  <div class="col-xs-12 sponsor">
    <img src="/static/img/ico/nsf_logo.jpg">
    <img src="/static/img/ico/onr_logo.jpg">
    <img src="/static/img/ico/aro_logo.jpg">
    <img src="/static/img/ico/nvidia_logo.jpg">
  </div>
</div>
<br>
<div class="row">
  <div class="col-xs-12 sponsor">
    <img src="/static/img/ico/aara_logo.png">
    <img src="/static/img/ico/gfra_logo.jpg">
  </div>
</div>
<br>
<div class="row">
  <div class="col-xs-12 sponsor">
    <img src="/static/img/ico/paul_logo.jpg">
    <img src="/static/img/ico/ictas_logo.jpg">
  </div>
</div>
<br>
<br>
